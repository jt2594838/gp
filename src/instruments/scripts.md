# apply_map_dataset.sh
This shell applies the process maps generated by classifier or generator to a dataset and save the processed pics and their labels in an HDF5 file. The key of inputs in this HDF5 file is 'x' while the key of labels is 'y'.
## parameters
### dataset
The name of the dataset. Alternatives:  
- 'CIFAR_100'
- 'CIFAR_10'
- 'H5'  

The CIFAR datasets are simply pytorch built-in datasets. The H5 dataset is an HDF5 file with 2 datasets, 'x' for the inputs and 'y' for the labels. The inputs should be a 3d or 4d array, with each dimension representing [id, (depth,) height, width]. The labels are a 1d array, y[i] is the true label of x[i, :].

### dataset_dir
For the CIFAR datasets, this should be the directory that contains the dataset. For H5 dataset, this should be the path of the HDF5 file.

### apply_method_name
This decides how to process the dataset using the process map. Alternatives:  
- 'apply_zero4D'
- 'apply_one4D'
 
'apply_zero4D': set the pixel value at (x, y) to 0 if the value of process map at (x, y) is one.  
'apply_one4D': set the pixel value at (x, y) to 1 if the value of process map at (x, y) is one.  

### map_dir
The path of the HDF5 file that contains the process maps. The key of the maps should be 'map'.

### train
Whether use training data or validating data. Only valid when using CIFAR datasets. If you want to set this to false, you must **comment this line** like this.  

```
# train="-train 1"
```

### limit 
The number of samples you want to process. If this is smaller than the size of the dataset, only the first samples will be processed. This must not exceed the size of the dataset.


# datasetToH5.sh
This shell convert a dataset to HDF5 format, with key 'x' as inputs and key 'y' as labels.

## parameters
### dataset
The name of the dataset. Alternatives:  
- 'CIFAR_100'
- 'CIFAR_10'

The CIFAR datasets are simply pytorch built-in datasets.

### input
For the CIFAR datasets, this should be the directory that contains the dataset. 

### output 
The path where the converted HDF5 file should be saved.

### train
Whether use training data or validating data. Only valid when using CIFAR datasets. If you want to set this to false, you must **comment this line** like this.  

```
# train="-train 1"
```

# export_diff.sh
This shell convert an HDF5 file that contains pics whose classification errors decrease after being processed to jpg pics.  
The naming of the jpg files is as followings:  
For unprocessed pictures : {id}\_{prediction}\_{true\_label}\_{loss}.jpg  
For processed pictures : {id}\_{prediction}\_{true\_label}\_{loss}\_{prediction\_changed}applied.jpg


## parameters
### input
The path of the HDF5 file to be converted.

### output
The directory where the jpgs should be saved.

# export_pic.sh
This shell exports the original pictures, the process maps and the processed pictures in an HDF5 file as jpg format.  
The naming of the jpg files is as followings:  
For unprocessed pictures : {id}\_{true\_label}.jpg  
For processed pictures : {id}\_{true\_label}\_applied.jpg  
For process maps : {id}\_{true\_label}\_map.jpg

## parameters
### input
The path of the HDF5 file to be converted.

### output
The directory where the jpgs should be saved.

### apply_method_name
This decides how to process the dataset using the process map and should be consistent with the process maps. Alternatives:  
- 'apply_zero'
- 'apply_one'

### use_map
If not set, only the original pictures will be exported.

# gen_map_classifier.sh
This shell generator process maps using a classifier. The gengerated process maps are stored in an HDF5 file with 'map' as their key. The original pictures and their labels are also stored in this file with key 'x' and 'y' for future convinience.
## parameters
### dataset
The name of the dataset. Alternatives:  
- 'CIFAR_100'
- 'CIFAR_10'
- 'H5'  

The CIFAR datasets are simply pytorch built-in datasets. The H5 dataset is an HDF5 file with 2 datasets, 'x' for the inputs and 'y' for the labels. The inputs should be a 3d or 4d array, with each dimension representing [id, (depth,) height, width]. The labels are a 1d array, y[i] is the true label of x[i, :].

### data_dir
For the CIFAR datasets, this should be the directory that contains the dataset. For H5 dataset, this should be the path of the HDF5 file.

### model_name
The name of the the classifier used to generate process maps.

### model_path
The path of the classifier. The file should be a PyTorch model file.

### apply_method_name
This decides how to process the dataset using the process map. When using superpixel method, this parameter is ignored. Alternatives:  
- 'apply_zero4D'
- 'apply_one4D'
 
'apply_zero4D': set the pixel value at (x, y) to 0 if the value of process map at (x, y) is one.  
'apply_one4D': set the pixel value at (x, y) to 1 if the value of process map at (x, y) is one.  

### size
The size of the square when using rectangular segmentaion, or the number of superpixels if using superpixel segmentation.

### gen_method_name
The segmentation method. Alternatives:  
- 'rect': rectangular segmentation
- 'rect_rnd': rectangular segmentation with rectangles randomly selected
- 'super\_pixel\_zero': SLIC superpixel segmentation, set a segment to zero
- 'super\_pixel\_zero_rnd': SLIC superpixel segmentation, set a segment to zero and randomly select superpixel
- 'super_pixel_one': SLIC superpixel segmentation, set a segment to one

### output_dir
The directory where the generated maps should be stored. The naming of the output file is :  
{model\_name}\_{dataset\_name}\_{offset}\_{length}\_{apply\_method\_name}\_{gen\_method\_name}\_{description}.h5

### offset
If set to n, then the generation will start from the nth picture.

### length
The number of process maps that should be generated. Warning: offset + length must < size of dataset.

### update_err
If set to true, then after each successful process (classification error is less than  the standard error), the standard error will be set to the new less error, which means we can find more effective and fewer non-critical areas.

### gpu_no
The number of GPU you want to use.

### description
Other description you want to make for the results. This will be added to the name of the output file.

# gen_map_generator
This shell generator process maps using a generator. The gengerated process maps are stored in an HDF5 file with 'map' as their key. The original pictures and their labels are also stored in this file with key 'x' and 'y' for future convinience.

## parameters
### dataset
The name of the dataset. Alternatives:  
- 'CIFAR_100'
- 'CIFAR_10'
- 'H5'  

The CIFAR datasets are simply pytorch built-in datasets. The H5 dataset is an HDF5 file with 2 datasets, 'x' for the inputs and 'y' for the labels. The inputs should be a 3d or 4d array, with each dimension representing [id, (depth,) height, width]. The labels are a 1d array, y[i] is the true label of x[i, :].

### data_dir
For the CIFAR datasets, this should be the directory that contains the dataset. For H5 dataset, this should be the path of the HDF5 file.

### classes
How many different classes (labels) are in the dataset.

### model_name
The name of the the generator used to generate process maps.

### model_path
The path of the generator. The file should be a PyTorch model file.

### map_path
The directory where the generated maps should be stored. The naming of the output file is :  
{model\_name}\_{dataset\_name}\_{description}.h5

### limit
The number of process maps that should be generated. 

### gpu_no
The number of GPU you want to use.

### description
Other description you want to make for the results. This will be added to the name of the output file.

# pretrain_classifier.sh
This shell train a basic classifier as baseline and tool for generating training process maps.
## parameters
### batch_size
The number of pics in a batch.

### epoch
How many rounds will the training process continues.

### classes
How many different classes (labels) are in the dataset.

### dataset
The name of the dataset. Alternatives:  
- 'CIFAR_100'
- 'CIFAR_10'
- 'H5'  

The CIFAR datasets are simply pytorch built-in datasets. The H5 dataset is an HDF5 file with 2 datasets, 'x' for the inputs and 'y' for the labels. The inputs should be a 3d or 4d array, with each dimension representing [id, (depth,) height, width]. The labels are a 1d array, y[i] is the true label of x[i, :].

### train_dir 
The path of the training data. For the CIFAR datasets, this should be the directory that contains the dataset. For H5 dataset, this should be the path of the HDF5 file.

### val_dir
The path of the validating data. For the CIFAR datasets, this should be the directory that contains the dataset. For H5 dataset, this should be the path of the HDF5 file.

### in_channels
The depth of the input picture.

### pre_trained
Whether the classifier should use the PyTorch pre-trained model.

### model
The name of the the classifier.

### model_path
The directory where the classifier should be saved. The naming of the model file is:  
{model\_name}\_{dataset}\_{classes}\_{epoch}\_{validating\_precision}.pkl

### gpu_no
The number of GPU you want to use.

# split_data.sh
This shell split an H5 dataset into training set, validation set and test set.
## parameters
### input
The HDF5 file to be split.

### train_rate
The percentage of training data among total data.

### val_rate
The percentage of validation data among total data. The rest will be test data.

### classes
How many different classes (labels) are in the dataset.

### output
The directory where the split files should be stored.

# test_map_diff.sh
This shell find pictures that have lower classification errors after being processed under certain threshold.
## parameters
### model
The name of the the classifier.

### model_path
The directory where the classifier is saved. The file should be a PyTorch model file.

### classes
How many different classes (labels) are in the dataset.

### dataset
The name of the dataset. Alternatives:  
- 'CIFAR_100'
- 'CIFAR_10'
- 'H5'  

The CIFAR datasets are simply pytorch built-in datasets. The H5 dataset is an HDF5 file with 2 datasets, 'x' for the inputs and 'y' for the labels. The inputs should be a 3d or 4d array, with each dimension representing [id, (depth,) height, width]. The labels are a 1d array, y[i] is the true label of x[i, :].

### map_dir 
The path of the HDF5 file that contains input pictures, their labels and process maps.

### threhsold
The threshold used to binarize process maps. A single float.

### apply_method
This decides how to process the dataset using the process map. When using superpixel method, this parameter is ignored. Alternatives:  
- 'apply_zero4D'
- 'apply_one4D'
 
'apply_zero4D': set the pixel value at (x, y) to 0 if the value of process map at (x, y) is one.  
'apply_one4D': set the pixel value at (x, y) to 1 if the value of process map at (x, y) is one.  

### gpu_no
The number of GPU you want to use.

### output
The path of the output HDF5 file. The file has following datasets:  
- x0 : unprocessed picture
- y0 : prediction of unprocessed picture
- loss0 : classification error of unprocessed picture
- x1 : processed picture
- y1 : prediction of processed picture
- loss1 : classification error of processed picture
- label : true label of the picture
- id : the id of the picture in the dataset


# test\_map\_validate
This shell used different threshold to binarize the process maps generated by generator and use them to process the picture, observing the classification after process.
## parameters
### batch_size
The number of pics in a batch.

### classes
How many different classes (labels) are in the dataset.

### dataset
The name of the dataset. Alternatives:  
- 'CIFAR_100'
- 'CIFAR_10'
- 'H5'  

The CIFAR datasets are simply pytorch built-in datasets. The H5 dataset is an HDF5 file with 2 datasets, 'x' for the inputs and 'y' for the labels. The inputs should be a 3d or 4d array, with each dimension representing [id, (depth,) height, width]. The labels are a 1d array, y[i] is the true label of x[i, :].

### map_dir 
The path of the HDF5 file that contains input pictures, their labels and process maps. If a directory is given, all HDF5 files under this directory will be used respectively.

### threhsold
The thresholds used to binarize process maps. Float string separated by comma.

### model
The name of the the classifier.

### model_path
The directory where the classifier is saved. The file should be a PyTorch model file.

### apply_method
This decides how to process the dataset using the process map. When using superpixel method, this parameter is ignored. Alternatives:  
- 'apply_zero4D'
- 'apply_one4D'
 
'apply_zero4D': set the pixel value at (x, y) to 0 if the value of process map at (x, y) is one.  
'apply_one4D': set the pixel value at (x, y) to 1 if the value of process map at (x, y) is one. 

### gpu_no
The number of GPU you want to use.

### output
The path of the output file. The file is a multi-line file, each line contains:  
- fullpath of the map file
- threshold 
- overall precision
- overall recall
- precision of each class
- recall of each class
- classicifation error
 

# train_generator.sh
### batch_size
The number of pics in a batch.

### epoch
How many rounds will the training process continues.

### classes
How many different classes (labels) are in the dataset.

### dataset
The name of the dataset. Alternatives:  
- 'CIFAR_100'
- 'CIFAR_10'
- 'H5'  

The CIFAR datasets are simply pytorch built-in datasets. The H5 dataset is an HDF5 file with 2 datasets, 'x' for the inputs and 'y' for the labels. The inputs should be a 3d or 4d array, with each dimension representing [id, (depth,) height, width]. The labels are a 1d array, y[i] is the true label of x[i, :].

### in_channels
The depth of the input picture.

### pre_trained
Whether the classifier should use the PyTorch pre-trained model.

### model
The name of the the generator. Alternatives:
- ConvDeconvV2
- Deeplab

### model_path
The directory where the generator should be saved. The naming of the model file is:  
{model\_name}\_{dataset}\_{classes}\_{epoch}\_{loss}\_{description}.pkl

### train_dir 
The path of the training data. This should be an HDF5 file containing both pictures and process maps.

### val_dir
The path of the validating data. This should be an HDF5 file containing both pictures and process maps.

### description
Other description you want to make for the results. This will be added to the name of the output file.

### preprocess
If set, the input maps will be binarized with a threshold of 0.

### gpu_no
The number of GPU you want to use.

### learn_rate
The rate of updating network weights.